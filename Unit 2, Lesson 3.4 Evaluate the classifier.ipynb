{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from nltk.corpus import stopwords "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "# Naive Bayes Classifier: Feedback analysis #\n",
    "\n",
    "Using data from the Yelp Reviews dataset, let's build a Naive Bayes classifier to classify the sentiment polarity of restaurant reviews (positive or negative). We will start by exploring the data, and then we'll extract some features to start modeling. We will use unigrams to build and test a classifier. To demonstrate the problem of overfitting, the classifier built based on Yelp Review data will be tested on an additional, unseen dataset (as per Lesson 2.7 Challenge). \n",
    "\n",
    "To cross-validate and refine the model further, the classifier will be evaluated using 5 folds. Finally, we'll retest it on the unseen dataset to see how well the cross-validation has improved the classifer.\n",
    "\n",
    "## Overview of the data ##\n",
    "\n",
    "The dataset of 1000 rows includes just the review text and a sentiment polarity: 1 = positive, 0 = negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0                           Wow... Loved this place.          1\n",
       "1                                 Crust is not good.          0\n",
       "2          Not tasty and the texture was just nasty.          0\n",
       "3  Stopped by during the late May bank holiday of...          1\n",
       "4  The selection on the menu was great and so wer...          1"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grab and process the raw data.\n",
    "yelp_raw = pd.read_csv('/Users/teresaoneill/Dropbox/Thinkful/Datasets/yelp_labelled.txt', delimiter= '\\t', header=None, encoding='utf-8')\n",
    "yelp_raw.columns = ['review', 'sentiment']\n",
    "yelp_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset includes two balanced classes, with 500 observations in each, so we do not need to employ any special sampling strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    500\n",
       "0    500\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check how many datapoints are in each category.\n",
    "yelp_raw['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "For our first try, let's construct a set of keywords for negative sentiment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "keywords_neg = ['suck', 'else', 'wait', 'gross', 'bad', 'waste', 'rude', 'never', 'terrible']\n",
    "\n",
    "for key in keywords_neg:\n",
    "    # Note that we add spaces around the key so that we're getting the word,\n",
    "    # not just pattern matching.\n",
    "    yelp_raw[str(key)] = yelp_raw.review.str.contains(\n",
    "        ' ' + str(key),\n",
    "        case=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "Let's check how independent these keywords are with a heatmap. The keywords we've chosen are pretty independent, so we're not violating the assumptions of the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a164e2ba8>"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAElCAYAAADgCEWlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n7PHjAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a164e27b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(yelp_raw.corr(), cmap=\"YlGnBu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "Next, let's specify the outcome and input variables, and try the model. \n",
    "\n",
    "### Iteration 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "data = yelp_raw[keywords_neg]\n",
    "target = yelp_raw['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 1000 points : 417\n"
     ]
    }
   ],
   "source": [
    "# For the binary classifier, we'll use a Bernoulli distribution.\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "# Instantiate the model and store it in a new variable.\n",
    "bnb = BernoulliNB()\n",
    "\n",
    "# Fit our model to the data.\n",
    "bnb.fit(data, target)\n",
    "\n",
    "# Classify, storing the result in a new variable.\n",
    "y_pred1 = bnb.predict(data)\n",
    "\n",
    "# Display our results.\n",
    "print(\"Number of mislabeled points out of a total {} points : {}\".format(\n",
    "    data.shape[0],\n",
    "    (target != y_pred1).sum()\n",
    "))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "So far, the model is faring just a little better than chance, so it needs to be refined. A confusion matrix will narrow in on the model's weakness: sensitivity or specificity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 94 406]\n",
      " [ 11 489]]\n",
      "2.2\n",
      "81.2\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "confusion1 = confusion_matrix(target, y_pred1)\n",
    "print(confusion1)\n",
    "\n",
    "type1_error = confusion1[1][0]/(confusion1[1][0]+confusion1[1][1])*100\n",
    "print(type1_error)\n",
    "\n",
    "type2_error = confusion1[0][1]/(confusion1[0][0]+confusion1[0][1])*100\n",
    "print(type2_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model's Type 1 error rate is pretty good: only 11 positive reviews were misclassified as negative reviews (2.2%), while the Type 2 error rate is quite high: 94 negative reviews were missed (18.8%).\n",
    "\n",
    "### Iteration 2 ###\n",
    "\n",
    "To refine the model, let's construct a bag of words and examine which unigrams occur most frequently in reviews with each sentiment. We'll start by cleaning and tokenizing the reviews (stripping non-alphabetic characters, casting to lowercase, and separating into words). The CountVectorizer function from sklearn takes care of tokenization. We could manually remove stopwords, but the term frequency - inverse document frequency transformer later should have the same effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start by removing nonalphabetic characters and converting to lowercase.\n",
    "\n",
    "yelp_token = yelp_raw['review'].str.replace('[^a-zA-Z]', ' ')\n",
    "yelp_token = yelp_raw['review'].str.lower()\n",
    "#words = yelp_token.str.split(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CountVectorizer generates an array where each row is a review from the original dataset, and each column is a word of at least two characters. Each item in the area is a Boolean indicating whether the word is present in that review. Since the highest frequency words contribute little information to the model, we'll transform the dataset so that more informative features are weighted more heavily. \n",
    "\n",
    "As we can see from the shape of the array, there are 1000 reviews (the original dataset) and 2034 unigrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 2034)\n"
     ]
    }
   ],
   "source": [
    "#Use CountVectorizer to generate an array of unigram counts for each review.\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(yelp_token)\n",
    "#counts = count_vectorizer.fit_transform(data['text'].values)\n",
    "\n",
    "#Use term frequency - inverse document frequency transformation to weight more informative unigrams.\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer().fit(X)\n",
    "X_tfidf = tfidf_transformer.transform(X)\n",
    "\n",
    "#Take a look at the shape of the array.\n",
    "print(X_tfidf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll refit the model using the transformed unigram array instead of the manually constructed list of negative keywords from Iteration 1. This model correctly accounts for 945/1000 datapoints: an accuracy of 94.5%--much better than our first model!\n",
    "\n",
    "**Question:** How do we test the assumption of independence in a bag of words model like this? What's the best way to look under the hood and see which words are doing the work?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 1000 points : 55\n"
     ]
    }
   ],
   "source": [
    "#Refit the model using tfidf in place of the manually constructed keywords list.\n",
    "bnb.fit(X_tfidf, target)\n",
    "y_pred2 = bnb.predict(X_tfidf)\n",
    "\n",
    "#Read out the result.\n",
    "print(\"Number of mislabeled points out of a total {} points : {}\".format(\n",
    "    data.shape[0],\n",
    "    (target != y_pred2).sum()\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's evaluate the model using a confusion matrix, to see where it can be improved. The Type 1 and 2 error rates are actually quite similar (5.8% and 5.2%, respectively). This is a really strong model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[474  26]\n",
      " [ 29 471]]\n",
      "5.8\n",
      "5.2\n"
     ]
    }
   ],
   "source": [
    "#Evaluate the result in a confusion matrix.\n",
    "confusion2 = confusion_matrix(target, y_pred2)\n",
    "print(confusion2)\n",
    "\n",
    "type1_error = confusion2[1][0]/(confusion2[1][0]+confusion2[1][1])*100\n",
    "print(type1_error)\n",
    "\n",
    "type2_error = confusion2[0][1]/(confusion2[0][0]+confusion2[0][1])*100\n",
    "print(type2_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The big problem**: Since it was constructed using the entire dataset, it suffers from overfitting. The model is built on the basis of all the data in the yelp reviews corpus, so we expect it to fare well with the yelp review corpus. If we apply it to unseen data, say, the Amazon review corpus, we will not expect the same performance. Let's run through the process, fitting the model to the Amazon data, to demonstrate the problem. \n",
    "\n",
    "First, read in the Amazon data, and confirm that it has the same content and shape as the Yelp data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    500\n",
      "0    500\n",
      "Name: sentiment, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So there is no way for me to plug it in here i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good case, Excellent value.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Great for the jawbone.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tied to charger for conversations lasting more...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The mic is great.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  So there is no way for me to plug it in here i...          0\n",
       "1                        Good case, Excellent value.          1\n",
       "2                             Great for the jawbone.          1\n",
       "3  Tied to charger for conversations lasting more...          0\n",
       "4                                  The mic is great.          1"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_raw = pd.read_csv('/Users/teresaoneill/Dropbox/Thinkful/Datasets/amazon_cells_labelled.txt', delimiter= '\\t', header=None, encoding='utf-8')\n",
    "amazon_raw.columns = ['review', 'sentiment']\n",
    "print(amazon_raw['sentiment'].value_counts())\n",
    "amazon_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 1000 points : 119\n",
      "[[423  77]\n",
      " [ 42 458]]\n",
      "8.4\n",
      "15.4\n"
     ]
    }
   ],
   "source": [
    "#Create a variable to store the Amazon target data.\n",
    "target_am = amazon_raw['sentiment']\n",
    "\n",
    "#Refit the model, using the overfitted features from the Yelp dataset.\n",
    "bnb.fit(X_tfidf, target_am)\n",
    "y_pred_am = bnb.predict(X_tfidf)\n",
    "\n",
    "#Read out the result.\n",
    "print(\"Number of mislabeled points out of a total {} points : {}\".format(\n",
    "    data.shape[0],\n",
    "    (target_am != y_pred_am).sum()\n",
    "))\n",
    "\n",
    "#Evaluate the result in a confusion matrix.\n",
    "confusion_am = confusion_matrix(target_am, y_pred_am)\n",
    "print(confusion_am)\n",
    "\n",
    "type1_error = confusion_am[1][0]/(confusion_am[1][0]+confusion_am[1][1])*100\n",
    "print(type1_error)\n",
    "\n",
    "type2_error = confusion_am[0][1]/(confusion_am[0][0]+confusion_am[0][1])*100\n",
    "print(type2_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the model performed very well on its Yelp training data, when confronted with unseen data, its performance isn't quite as good. Its Type 2 error rate jumped to 15.4%: the classifier is not specific enough.\n",
    "\n",
    "To improve the predictive power of the model, we need to divide the data into a training set and a test set, and cross-validate. Let's go back to the Yelp dataset, and try again.\n",
    "\n",
    "### Iteration 3 ###\n",
    "\n",
    "Let's rerun the model, cross-validating it using 5 folds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total reviews classified: 1000\n",
      "Score: 0.762921130068\n",
      "Confusion matrix:\n",
      "[[356 144]\n",
      " [ 93 407]]\n",
      "18.6\n",
      "28.8\n"
     ]
    }
   ],
   "source": [
    "#Collapse the bag of words vectorizer, tfidf transformer, and NB classifier into one operation.\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vectorizer',  CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('classifier',  BernoulliNB()) ])\n",
    "\n",
    "#Cross-validate using the k-folds method.\n",
    "\n",
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "k_fold = KFold(n=len(yelp_raw), n_folds=5)\n",
    "scores = []\n",
    "confusion3 = np.array([[0, 0], [0, 0]])\n",
    "for train_indices, test_indices in k_fold:\n",
    "    train_text = yelp_raw.iloc[train_indices]['review'].values\n",
    "    train_y = yelp_raw.iloc[train_indices]['sentiment'].values\n",
    "\n",
    "    test_text = yelp_raw.iloc[test_indices]['review'].values\n",
    "    test_y = yelp_raw.iloc[test_indices]['sentiment'].values\n",
    "\n",
    "    pipeline.fit(train_text, train_y)\n",
    "    predictions = pipeline.predict(test_text)\n",
    "\n",
    "    confusion3 += confusion_matrix(test_y, predictions)\n",
    "    score3 = f1_score(test_y, predictions)\n",
    "    scores.append(score3)\n",
    "\n",
    "print('Total reviews classified:', len(yelp_raw))\n",
    "print('Score:', sum(scores)/len(scores))\n",
    "print('Confusion matrix:')\n",
    "print(confusion3)\n",
    "\n",
    "type1_error = confusion3[1][0]/(confusion3[1][0]+confusion3[1][1])*100\n",
    "print(type1_error)\n",
    "\n",
    "type2_error = confusion3[0][1]/(confusion3[0][0]+confusion3[0][1])*100\n",
    "print(type2_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After cross-validation over 5 folds of the data, we end up with a much less accurate classifier. Its Type 1 error rate is now 18.6%, and Type 2 error is 28.8%. \n",
    "\n",
    "** Question:** Why did it get so much worse with cross-validation? I understand that this means there is less data available for training the model, but this loss of accuracy is pretty bad!\n",
    "\n",
    "### Iteration 4 ###\n",
    "\n",
    "That didn't go so well! Let's try again, enriching the model with bigrams. Because of examples like, \"not disappointed,\" simple unigrams (e.g., \"disappointed\") might not be strong enough. Adding bigrams will increase the model's complexity, but it should improve upon unigrams. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total reviews classified: 1000\n",
      "Score: 0.742006076294\n",
      "Confusion matrix:\n",
      "[[297 203]\n",
      " [ 84 416]]\n",
      "16.8\n",
      "40.6\n"
     ]
    }
   ],
   "source": [
    "#Try again, this time with bigrams.\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vectorizer',  CountVectorizer(ngram_range=(1, 2))),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('classifier',  BernoulliNB()) ])\n",
    "\n",
    "#Cross-validate using the k-folds method.\n",
    "\n",
    "k_fold = KFold(n=len(yelp_raw), n_folds=5)\n",
    "scores = []\n",
    "confusion4 = np.array([[0, 0], [0, 0]])\n",
    "for train_indices, test_indices in k_fold:\n",
    "    train_text = yelp_raw.iloc[train_indices]['review'].values\n",
    "    train_y = yelp_raw.iloc[train_indices]['sentiment'].values\n",
    "\n",
    "    test_text = yelp_raw.iloc[test_indices]['review'].values\n",
    "    test_y = yelp_raw.iloc[test_indices]['sentiment'].values\n",
    "\n",
    "    pipeline.fit(train_text, train_y)\n",
    "    predictions = pipeline.predict(test_text)\n",
    "\n",
    "    confusion4 += confusion_matrix(test_y, predictions)\n",
    "    score4 = f1_score(test_y, predictions)\n",
    "    scores.append(score4)\n",
    "\n",
    "print('Total reviews classified:', len(yelp_raw))\n",
    "print('Score:', sum(scores)/len(scores))\n",
    "print('Confusion matrix:')\n",
    "print(confusion4)\n",
    "\n",
    "type1_error = confusion4[1][0]/(confusion4[1][0]+confusion4[1][1])*100\n",
    "print(type1_error)\n",
    "\n",
    "type2_error = confusion4[0][1]/(confusion4[0][0]+confusion4[0][1])*100\n",
    "print(type2_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yikes! This result is even worse. With bigrams in the mix, the classifier is misclassifying 40.6% of negative reviews as positive. Why is this the case? \n",
    "\n",
    "**NOTE: I don't understand why it's getting so much worse...**\n",
    "\n",
    "One thing we can try is controlling for the length of the review, binarizing the classifier so that reviews with more instances of a given features are not weighted differently from those with just one instance. Let's try that on the unigram model, and see what happens. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total reviews classified: 1000\n",
      "Score: 0.436363636364\n",
      "Confusion matrix:\n",
      "[[356 144]\n",
      " [ 93 407]]\n",
      "18.6\n",
      "28.8\n"
     ]
    }
   ],
   "source": [
    "#Try again, this time with bigrams.\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vectorizer',  CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('classifier',  BernoulliNB(binarize=0.0)) ])\n",
    "\n",
    "#Cross-validate using the k-folds method.\n",
    "\n",
    "k_fold = KFold(n=len(yelp_raw), n_folds=5)\n",
    "scores = []\n",
    "confusion5 = np.array([[0, 0], [0, 0]])\n",
    "for train_indices, test_indices in k_fold:\n",
    "    train_text = yelp_raw.iloc[train_indices]['review'].values\n",
    "    train_y = yelp_raw.iloc[train_indices]['sentiment'].values\n",
    "\n",
    "    test_text = yelp_raw.iloc[test_indices]['review'].values\n",
    "    test_y = yelp_raw.iloc[test_indices]['sentiment'].values\n",
    "\n",
    "    pipeline.fit(train_text, train_y)\n",
    "    predictions = pipeline.predict(test_text)\n",
    "\n",
    "    confusion5 += confusion_matrix(test_y, predictions)\n",
    "    score5 = f1_score(test_y, predictions)\n",
    "    scores.append(score4)\n",
    "\n",
    "print('Total reviews classified:', len(yelp_raw))\n",
    "print('Score:', sum(scores)/len(scores))\n",
    "print('Confusion matrix:')\n",
    "print(confusion5)\n",
    "\n",
    "type1_error = confusion5[1][0]/(confusion5[1][0]+confusion5[1][1])*100\n",
    "print(type1_error)\n",
    "\n",
    "type2_error = confusion5[0][1]/(confusion5[0][0]+confusion5[0][1])*100\n",
    "print(type2_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're back where we started from in Iteration 3. Binarizing the classifier doesn't seem to make a difference. Since the reviews are generally rather short, this is not surprising. Binarizing might be more important in a context like spam email classification, where there is more variance in length.\n",
    "\n",
    "### Summary ###\n",
    "\n",
    "After 5 iterations, implementing cross-validation to avoid overfitting the model, we have not gained any predictive power. In the session, I'd like to check in about why I might've gotten this result, and about how I can look under the hood of the model to see which features are being extracted after the tf-idf transformation. \n"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "49px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
